This Project was inspired by Fisayomi Fashanu of Cloud Career Mentor. One of the benefits of the cloud deployment is that infrastructure can be scaled easier and quicker compared to on premises deployment.

Project Scenario
A company has an ec2 instance hosting a web server, everything is stable until the marketing department starts running a sales promotion that proves to be very popular with its customers, as a result of this the website receives a spike in traffic at different times. Every time there is a spike in traffic the server gets overloaded until it fails, which causes the website to go down, this then leads to customers being disgruntled because they cant access the site. The tech department then considers some scaling options like vertical scaling which is when the instance resources are increased e.g if the original instance 2vCpu and 5 Gig of RAM, vertical scaling will be making it 5vCpu and 10 Gig of RAM, but after digging deeper into the data they realized that the spike only occurs once or twice a week and then the cost of having a larger instance far outweighs the benefits.
After some extra consideration your tech leads decides on horizontal scaling, which is where more instances are added to meet the increase in demand, this means rather than have one big instance you can have two or three smaller instances that can be scaled up or down depending on traffic levels through auto-scaling. 
My task is now to setup auto scaling so this solution happens automaticaly. The goal is to create a webserver that can scale up and down to meet traffic demands for example if the website is getting alot of traffic then it adds more ec2 instances to deal with the increase workload and when the traffic goes down it reduces the number of ec2 instances to save on cost.

Steps of creating this solution
Step 1: create 3 public and 3 private subnets where all the other resources are going to be created
Step 2: Create an ec2 userdata script, which means when a new ec2 instance is created and deployed it automatically configured with the instanr settings like apache or Nginx webserver
step 3: create an auto scaling group and configure it
step 4: create an application load balancer in the public subnet and connect it to the autoscaling group configurations
step 5: create auto scaling policies that trigger the scaling activities, this can be achieved in one or two ways. The first way is to create a cloud watch alarm that monitors the cpu utilization of the ec2 instances, if the average cpu utlization goes above 70%, then the auto scaling group will add a new instance to deal with the increase workload. create a second cloud watch alarm that also monitors the cpu utlization of the ec2 instances, this time its triggered if the average cpu utlization goes below 20%, this shows there is less traffic going to the instances which means there is an excess of ec2 instances and some of this instances can be terminated
The second way to trigger scaling is with a method called target tracking, this is where you set a policy that you always want the average cpu utilization to be about 30%, this means that ec2 instances get added or removed automatically to make sure the average cpu utilization always stays above 30%.

it is also important to highlight that this implemention includes security because i'm putting the webservice in a private subnet rather than a public subnet, which is what most people do. it is also important to emphasize your understanding of cost saving because not only are you scaling up or down to meet the increase demand but you also have triggers that reduce the number
